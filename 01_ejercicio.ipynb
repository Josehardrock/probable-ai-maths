{"cells":[{"cell_type":"markdown","metadata":{},"source":["Ejercicio 1.\n","Implemente el algoritmo de Descenso del Gradiente desde cero y encuentre los mínimos locales\n","del siguiente conjunto de funciones polinomiales y trigonométricas.\n","\n","a) g(x) = x³ + 3x² -2\n","b) g(x) = x² sin(x) + x  \n","c) g(x) = 4x² − 10x + 4\n","d) g(x) = x^4 − 4x³ + 4\n","\n","Instrucciones:\n","1. Implementación del Algoritmo:\n","a. Defina una función gradient_descent que acepte como argumentos la función, su\n","derivada, un punto inicial x_start, una tasa de aprendizaje lr, y un número máximo\n","de iteraciones max_iters.\n","b. Esta función debe retornar la trayectoria de puntos por los que pasó el algoritmo y\n","el último punto obtenido.\n","2. Aplicación del Algoritmo:\n","a. Aplique el algoritmo a cada una de las funciones anteriormente indicadas con\n","diferentes puntos iniciales y tasas de aprendizaje.\n","b. Documente los mínimos que encuentres.\n","3. Visualización del Algoritmo:\n","a. Utilizando matplotlib grafique cada función y el camino que sigue el algoritmo de\n","descenso del gradiente.\n","Preguntas de Reflexión:\n","• ¿Cómo afecta la tasa de aprendizaje a la convergencia del algoritmo?\n","• ¿Qué impacto tiene el punto inicial en la localización de mínimos?\n","• ¿En qué funciones el algoritmo enfrenta más dificultades para encontrar el mínimo y por\n","qué?\n"]},{"cell_type":"code","execution_count":50,"metadata":{},"outputs":[],"source":["import math\n","import numpy as np\n","\n","import sympy as sp\n","\n","import matplotlib.pyplot as plt\n","from mpl_toolkits.mplot3d import Axes3D\n","\n","import inspect"]},{"cell_type":"code","execution_count":72,"metadata":{},"outputs":[],"source":["# a) g(x) = x³ + 3x² -2\n","# b) g(x) = x² sin(x) + x\n","# c) g(x) = 4x² − 10x + 4\n","# d) g(x) = x^4 − 4x³ + 4\n","\n","# Instrucciones:\n","# 1. Implementación del Algoritmo:\n","# a. Defina una función gradient_descent que acepte como argumentos la función, \n","# su derivada, un punto inicial x_start, una tasa de aprendizaje lr, y un número máximo\n","# de iteraciones max_iters.\n","# b. Esta función debe retornar la trayectoria de puntos por los que pasó el algoritmo y el último punto obtenido.\n","\n","def gradient_descent(func, d_func, dx_start, lr=0.01, max_iters=1000) :\n","\n","    text = f\"Function : {inspect.getsource(func)}, Derived function : {inspect.getsource(d_func)}\"\n","    clean_text = text.replace(\"\\n\", \"\")\n","    print(clean_text)\n","\n","    x = dx_start\n","    trajectory = [x]\n","    for i in range(max_iters):\n","        gradient = d_func(x)\n","        x = x - lr * gradient\n","\n","        trajectory.append(x)\n","\n","        #print(f\"Current iteration : {str(i)}, Current point :  {str(x)}, Current gradient : {str(gradient)}\")\n","    print(f\"Trajectory : {trajectory} \\r\")\n","    print(\"\")\n","    return trajectory, x\n","\n"]},{"cell_type":"code","execution_count":73,"metadata":{},"outputs":[{"name":"stdout","output_type":"stream","text":["Function : def a(x) : return x**3 + 3*x**2 - 2, Derived function : def f_a(x) : return 3*x**2 + 6*x\n","Trajectory : [0.1, 0.0937, 0.0878146093, 0.08231439057380464, 0.07717225737251027, 0.07236325521092059, 0.06786436667712373, 0.0636543375085617, 0.05971352101753838, 0.05602373861871671, 0.052568154522929164] \n","\n","Function : def b(x) : return x**2 * sp.sin(x) + x, Derived function : def f_b(x) : return 2*x*sp.sin(x) + x**2*sp.cos(x) + 1\n","Trajectory : [0.1, 0.0897008327501785, 0.0794599847808991, 0.0692709001686301, 0.0591271382525132, 0.0490223595244628, 0.0389503118921210, 0.0289048172668036, 0.0188797584296347, 0.00886906613003441, -0.00113329362842437] \n","\n","Function : def c(x) : return 4*x**2 - 10*x + 4, Derived function : def f_c(x) : return 8*x - 10\n","Trajectory : [0.1, 0.192, 0.27664, 0.3545088, 0.42614809600000003, 0.49205624832000006, 0.5526917484544001, 0.6084764085780481, 0.6597982958918043, 0.7070144322204599, 0.7504532776428231] \n","\n","Function : def d(x) : return x**4 - 4*x**3 + 4, Derived function : def f_d(x) : return 4*x**3 - 12*x**2\n","Trajectory : [0.1, 0.10116, 0.10234659326236416, 0.10356068977387885, 0.10480324097421331, 0.10607524211715516, 0.10737773479349959, 0.10871180962853452, 0.11007860916825137, 0.11147933096972153, 0.11291523091252684] \n","\n"]}],"source":["def a(x) : return x**3 + 3*x**2 - 2\n","def f_a(x) : return 3*x**2 + 6*x\n","\n","def b(x) : return x**2 * sp.sin(x) + x\n","def f_b(x) : return 2*x*sp.sin(x) + x**2*sp.cos(x) + 1\n","\n","def c(x) : return 4*x**2 - 10*x + 4\n","def f_c(x) : return 8*x - 10\n","\n","def d(x) : return x**4 - 4*x**3 + 4\n","def f_d(x) : return 4*x**3 - 12*x**2\n","\n","traject, lastpoint = gradient_descent(a, f_a, 0.1, 0.01, 10)\n","traject, lastpoint = gradient_descent(b, f_b, 0.1, 0.01, 10)\n","traject, lastpoint = gradient_descent(c, f_c, 0.1, 0.01, 10)\n","traject, lastpoint = gradient_descent(d, f_d, 0.1, 0.01, 10)"]},{"cell_type":"code","execution_count":64,"metadata":{},"outputs":[],"source":["\n","# a) g(x) = x³ + 3x² -2, => g'(x) = 3x + 6x\n","# calc_derived(a, \"a\")\n","\n","# # b) g(x) = x² sin(x) + x => g'(x) = (2x sin (x) + x² cos(x)  ) + 1  => \n","# calc_derived(b, \"b\")\n","\n","# # c) g(x) = 4x² − 10x + 4 => g'(x) = 8x - 10\n","# calc_derived(c, \"c\")\n","\n","# # d) g(x) = x^4 - 4x³ + 4 => 4x²  - 12x² \n","# calc_derived(d, \"d\")\n","\n","# gradient_descent(a, x_a, 0, 0.1, 100)"]}],"metadata":{"kernelspec":{"display_name":"obspython3-9","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.9.18"}},"nbformat":4,"nbformat_minor":2}
