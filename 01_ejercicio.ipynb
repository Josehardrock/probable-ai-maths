{"cells":[{"cell_type":"markdown","metadata":{},"source":["Ejercicio 1.<br>\n","Implemente el algoritmo de Descenso del Gradiente desde cero y encuentre los mínimos locales del siguiente conjunto de funciones polinomiales y trigonométricas.\n","$$\n","a) g(x) = x³ + 3x² -2\n","$$\n","$$\n","b) g(x) = x² sin(x) + x  \n","$$\n","$$\n","c) g(x) = 4x² − 10x + 4\n","$$\n","$$\n","d) g(x) = x^4 − 4x³ + 4\n","$$\n","Instrucciones:\n","1. Implementación del Algoritmo: <br>\n","    a. Defina una función gradient_descent que acepte como argumentos la función, su derivada, un punto inicial x_start, una tasa de aprendizaje lr, y un número máximo de iteraciones max_iters. <br>\n","    b. Esta función debe retornar la trayectoria de puntos por los que pasó el algoritmo y el último punto obtenido.<br>\n","2. Aplicación del Algoritmo:<br>\n","    a. Aplique el algoritmo a cada una de las funciones anteriormente indicadas con diferentes puntos iniciales y tasas de aprendizaje.<br>\n","    b. Documente los mínimos que encuentres.<br>\n","3. Visualización del Algoritmo:<br>\n","    a. Utilizando matplotlib grafique cada función y el camino que sigue el algoritmo de descenso del gradiente.<br>\n","Preguntas de Reflexión:<br>\n","• ¿Cómo afecta la tasa de aprendizaje a la convergencia del algoritmo? <br>\n","• ¿Qué impacto tiene el punto inicial en la localización de mínimos? <br>\n","• ¿En qué funciones el algoritmo enfrenta más dificultades para encontrar el mínimo y porqué? <br>"]},{"cell_type":"code","execution_count":108,"metadata":{},"outputs":[],"source":["import math\n","import numpy as np\n","\n","import sympy as sp\n","\n","import matplotlib.pyplot as plt\n","from mpl_toolkits.mplot3d import Axes3D\n","\n","import inspect"]},{"cell_type":"code","execution_count":137,"metadata":{},"outputs":[],"source":["def gradient_descent(func, d_func, dx_start, lr=0.01, max_iters=1000) :\n","\n","    \"\"\"\n","    Function to eval the gradient descent algorithm. \n","    :param func: function to minimize\n","    :param d_func: derivative of the function\n","    :param dx_start: starting point\n","    :param lr: learning rate\n","    :param max_iters: maximum number of iterations\n","    \"\"\"\n","    point = dx_start\n","    trajectory = [point]\n","    for i in range(max_iters):\n","        gradient = d_func(point)\n","        point = point - lr * gradient\n","\n","        trajectory.append(x)\n","        print(f\"Current iteration : {str(i)}, Current point :  {str(x)}, Current gradient : {str(gradient)}\")\n","    print(f\"Trajectory : {trajectory}, LastPoint : {point} \\r\")\n","    return trajectory, point\n","\n","def plot_gradient_descent(func, trajectory, last_point) :\n","    \"\"\"\n","    Function to plot the gradient descent algorithm\n","    :param func: function to plot\n","    :param trajectory: trajectory of the algorithm\n","    :param point: last point\n","    \"\"\"\n","    x_s = np.linspace(-10, 10, 100)\n","    y_s = func(x_s)\n","\n","    plt.plot(x_s, y_s, label=\"Function\", color=\"blue\")\n","    plt.scatter(trajectory, func(np.array(trajectory)), color=\"red\", label=\"Trajectory\")\n","    plt.xlabel(\"x\")\n","    plt.ylabel(\"f(x)\")\n","    plt.scatter(last_point, func(last_point), color=\"green\", label=\"Last Point\")\n","    plt.title(f\"Gradient Descent {func}\")\n","    plt.legend()\n","    plt.show()\n","\n","\n"]},{"cell_type":"markdown","metadata":{},"source":["$$\n"," a)  f(x) = x^3 + 3x^2 - 2, f'(x) = 3x^2 + 6x\n","$$"]},{"cell_type":"code","execution_count":139,"metadata":{},"outputs":[{"ename":"TypeError","evalue":"'Add' object is not callable","output_type":"error","traceback":["\u001b[1;31m---------------------------------------------------------------------------\u001b[0m","\u001b[1;31mTypeError\u001b[0m                                 Traceback (most recent call last)","Cell \u001b[1;32mIn[139], line 5\u001b[0m\n\u001b[0;32m      2\u001b[0m f \u001b[38;5;241m=\u001b[39m x\u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39m\u001b[38;5;241m3\u001b[39m \u001b[38;5;241m+\u001b[39m \u001b[38;5;241m3\u001b[39m\u001b[38;5;241m*\u001b[39mx\u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39m\u001b[38;5;241m2\u001b[39m \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m2\u001b[39m\n\u001b[0;32m      3\u001b[0m f_x \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m3\u001b[39m\u001b[38;5;241m*\u001b[39mx\u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39m\u001b[38;5;241m2\u001b[39m \u001b[38;5;241m+\u001b[39m \u001b[38;5;241m6\u001b[39m\u001b[38;5;241m*\u001b[39mx\u001b[38;5;241m*\u001b[39m \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m2\u001b[39m\n\u001b[1;32m----> 5\u001b[0m traject, final_point \u001b[38;5;241m=\u001b[39m \u001b[43mgradient_descent\u001b[49m\u001b[43m(\u001b[49m\u001b[43mf\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mf_x\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m0.1\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m0.01\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m10\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[0;32m      6\u001b[0m plot_gradient_descent\n\u001b[0;32m      8\u001b[0m \u001b[38;5;66;03m# traject2, lastpoint2 = gradient_descent2(expr, 0.1, 0.1, 10)\u001b[39;00m\n","Cell \u001b[1;32mIn[137], line 14\u001b[0m, in \u001b[0;36mgradient_descent\u001b[1;34m(func, d_func, dx_start, lr, max_iters)\u001b[0m\n\u001b[0;32m     12\u001b[0m trajectory \u001b[38;5;241m=\u001b[39m [point]\n\u001b[0;32m     13\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m i \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(max_iters):\n\u001b[1;32m---> 14\u001b[0m     gradient \u001b[38;5;241m=\u001b[39m \u001b[43md_func\u001b[49m\u001b[43m(\u001b[49m\u001b[43mpoint\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     15\u001b[0m     point \u001b[38;5;241m=\u001b[39m point \u001b[38;5;241m-\u001b[39m lr \u001b[38;5;241m*\u001b[39m gradient\n\u001b[0;32m     17\u001b[0m     trajectory\u001b[38;5;241m.\u001b[39mappend(x)\n","\u001b[1;31mTypeError\u001b[0m: 'Add' object is not callable"]}],"source":["x=sp.Symbol('x')\n","f = x**3 + 3*x**2 -2\n","f_x = 3*x**2 + 6*x* -2\n","\n","traject, final_point = gradient_descent(f, f_x, 0.1, 0.01, 10)\n","plot_gradient_descent\n","\n","# traject2, lastpoint2 = gradient_descent2(expr, 0.1, 0.1, 10)\n","\n","sp.plot(f, (x))\n","sp.plot(f_x, (x))\n","\n","# x1=f_a.subs(x, 0.75)\n","# print(\"x1: \", x1)\n","# x2=f_a.subs(a, 0.5)\n","# print(\"x2: \",x2)\n","# x3=f_a.subs(a, 0)\n","# print(\"x3: \",x3)\n","# x3=f_a.subs(a, -0.1)\n","# print(\"x3: \",x3)\n","# x3=f_a.subs(a, -0.2)\n","# print(\"x3: \",x3)\n","# x3=f_a.subs(a, -0.3)\n","# print(\"x3: \",x3)\n","# x3=f_a.subs(a, -0.4)\n","# print(\"x3: \",x3)\n"]},{"cell_type":"markdown","metadata":{},"source":["$$\n","b)    g(x) = x² sin(x) + x    , g'(x)= 2x cos(x)\n","$$\n","$$\n","c)    g(x) = 4x² − 10x + 4    , g'(x) = 8x + 10\n","$$\n","$$\n","d)    g(x) = x^4 − 4x³ + 4    , g'(x) = 4x^3 + 12x^2\n","$$\n"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["\n","def b(x) : return x**2 * sp.sin(x) + x\n","def f_b(x) : return 2*x*sp.sin(x) + x**2*sp.cos(x) + 1\n","\n","def c(x) : return 4*x**2 - 10*x + 4\n","def f_c(x) : return 8*x - 10\n","\n","def d(x) : return x**4 - 4*x**3 + 4\n","def f_d(x) : return 4*x**3 - 12*x**2\n","\n","\n","\n","\n","traject, lastpoint = gradient_descent(b, f_b, 0.1, 0.01, 10)\n","traject, lastpoint = gradient_descent(c, f_c, 0.1, 0.01, 10)\n","traject, lastpoint = gradient_descent(d, f_d, 0.1, 0.01, 10)"]}],"metadata":{"kernelspec":{"display_name":"obspython3-9","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.9.18"}},"nbformat":4,"nbformat_minor":2}
